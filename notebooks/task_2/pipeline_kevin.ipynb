{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Model-Training/-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#1. load environment variables and data\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "#add working directory to sys path to execute utils/dataset.py\n",
    "working_dir = os.environ.get(\"WORKING_DIRECTORY\")\n",
    "sys.path.insert(0, working_dir)\n",
    "from utils.dataset import get_data \n",
    "df = get_data()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.dropna()\n",
    "#delete all data from df where quality > 10\n",
    "df = df[df[\"quality\"] <= 10]\n",
    "#onehot encode column \"wine type\"\n",
    "df = pd.get_dummies(df, columns=[\"wine type\"])\n",
    "\n",
    "X = df.drop(columns=[\"quality\"])\n",
    "y = df[\"quality\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pipeline and standard scaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline(steps=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        \"name\": \"LinearRegression\",\n",
    "        \"estimator\": LinearRegression(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"model__fit_intercept\": [True, False],\n",
    "                \"model__copy_X\": [True, False],\n",
    "                \"model__n_jobs\": [1,5,10,20],\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DecisionTreeRegressor\",\n",
    "        \"estimator\": DecisionTreeRegressor(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"model__criterion\": [\"squared_error\"],\n",
    "                \"model__splitter\": [\"best\", \"random\"],\n",
    "                \"model__max_depth\": [None, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5, 10]\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RandomForestRegressor\",\n",
    "        \"estimator\": RandomForestRegressor(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200],\n",
    "                \"model__criterion\": [\"squared_error\"],\n",
    "                \"model__max_depth\": [None, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5, 10]\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Gradient Boosting Regressor\",\n",
    "        \"estimator\": GradientBoostingRegressor(),\n",
    "        \"hyperparameters\":\n",
    "        {\n",
    "                \"model__n_estimators\": [100, 200, 500],\n",
    "                \"model__max_depth\": [None, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__learning_rate\": [0.01, 0.011, 0.012],\n",
    "                \"model__loss\": [\"squared_error\"],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Support Vector Machine\",\n",
    "        \"estimator\": svm.SVR(),\n",
    "        \"hyperparameters\":\n",
    "        {\n",
    "            \"model__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "            \"model__degree\": [1, 2, 3, 4, 5],\n",
    "            \"model__gamma\": [\"scale\", \"auto\"],\n",
    "            \"model__C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"model__epsilon\": [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    }\n",
    "    }\n",
    "]\n",
    "for model in models:\n",
    "    print(model[\"name\"])\n",
    "    print(\"-\"*len(model[\"name\"]))\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"model\", model[\"estimator\"])\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(pipeline, model[\"hyperparameters\"], cv=2)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\")\n",
    "    print(grid.best_params_)\n",
    "    print(\"\")\n",
    "\n",
    "    model[\"best_params\"] = grid.best_params_\n",
    "    model[\"best_score\"] = grid.best_score_\n",
    "    model[\"best_estimator\"] = grid.best_estimator_\n",
    "    model[\"best_model\"] = grid.best_estimator_.named_steps[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "models_to_save = []\n",
    "for model in models:\n",
    "    m = {\n",
    "        \"name\": model[\"name\"],\n",
    "        \"best_params\": model[\"best_params\"],\n",
    "        \"best_score\": model[\"best_score\"],\n",
    "    }\n",
    "    models_to_save.append(m)\n",
    "\n",
    "with open(\"best_models.json\", \"w\") as f:\n",
    "    json.dump(models_to_save, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_models(file: str = \"best_models.json\"):\n",
    "    try:\n",
    "        with open(file, \"r\") as f:\n",
    "            best_models = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file} not found\")\n",
    "        return None\n",
    "    \n",
    "    for model in best_models:\n",
    "        if model[\"name\"] == \"LinearRegression\":\n",
    "            model[\"estimator\"] = LinearRegression()\n",
    "        elif model[\"name\"] == \"DecisionTreeRegressor\":\n",
    "            model[\"estimator\"] = DecisionTreeRegressor()\n",
    "        elif model[\"name\"] == \"RandomForestRegressor\":\n",
    "            model[\"estimator\"] = RandomForestRegressor()\n",
    "        elif model[\"name\"] == \"Gradient Boosting Regressor\":\n",
    "            model[\"estimator\"] = GradientBoostingRegressor()\n",
    "        elif model[\"name\"] == \"Support Vector Machine\":\n",
    "            model[\"estimator\"] = svm.SVR()\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model['name']} not found\")\n",
    "    return best_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
