{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Model-Training/-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from wines: 8000it [00:00, 14933.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>minerals</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinot noir</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.1</td>\n",
       "      <td>76.729301</td>\n",
       "      <td>894.94</td>\n",
       "      <td>186.639301</td>\n",
       "      <td>109.91</td>\n",
       "      <td>0.048</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.99290</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.795712</td>\n",
       "      <td>1160.95</td>\n",
       "      <td>251.875712</td>\n",
       "      <td>247.08</td>\n",
       "      <td>0.039</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.99163</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.52</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.5</td>\n",
       "      <td>85.193710</td>\n",
       "      <td>789.82</td>\n",
       "      <td>304.703710</td>\n",
       "      <td>219.51</td>\n",
       "      <td>0.035</td>\n",
       "      <td>45.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.98949</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>17.5</td>\n",
       "      <td>11.976525</td>\n",
       "      <td>777.86</td>\n",
       "      <td>237.586525</td>\n",
       "      <td>225.61</td>\n",
       "      <td>0.045</td>\n",
       "      <td>48.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1.00014</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.19</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.599673</td>\n",
       "      <td>785.72</td>\n",
       "      <td>95.399673</td>\n",
       "      <td>89.80</td>\n",
       "      <td>0.041</td>\n",
       "      <td>62.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99508</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.37</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.3</td>\n",
       "      <td>22.403749</td>\n",
       "      <td>1044.95</td>\n",
       "      <td>289.523749</td>\n",
       "      <td>267.12</td>\n",
       "      <td>0.057</td>\n",
       "      <td>25.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.5</td>\n",
       "      <td>23.875866</td>\n",
       "      <td>888.61</td>\n",
       "      <td>133.545866</td>\n",
       "      <td>109.67</td>\n",
       "      <td>0.047</td>\n",
       "      <td>20.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99178</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.48</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.7</td>\n",
       "      <td>23.309699</td>\n",
       "      <td>1381.79</td>\n",
       "      <td>266.529699</td>\n",
       "      <td>243.22</td>\n",
       "      <td>0.052</td>\n",
       "      <td>56.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99398</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.7</td>\n",
       "      <td>49.165745</td>\n",
       "      <td>1456.41</td>\n",
       "      <td>269.915745</td>\n",
       "      <td>220.75</td>\n",
       "      <td>0.046</td>\n",
       "      <td>57.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gamay</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>8.9</td>\n",
       "      <td>54.450579</td>\n",
       "      <td>929.44</td>\n",
       "      <td>377.690579</td>\n",
       "      <td>323.24</td>\n",
       "      <td>0.036</td>\n",
       "      <td>8.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.99350</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wine type  fixed acidity  volatile acidity  citric acid  \\\n",
       "0          Pinot noir            5.8              0.15         0.49   \n",
       "1              Merlot            6.6              0.25         0.32   \n",
       "2          Chardonnay            6.7              0.21         0.34   \n",
       "3              Merlot            8.3              0.28         0.27   \n",
       "4              Merlot            7.5              0.42         0.19   \n",
       "5              Merlot            7.3              0.34         0.30   \n",
       "6              Merlot            7.6              0.21         0.49   \n",
       "7          Chardonnay            6.0              0.25         0.40   \n",
       "8  Cabernet Sauvignon            6.7              0.18         0.19   \n",
       "9               Gamay            7.7              0.28         0.39   \n",
       "\n",
       "   residual sugar  magnesium  flavanoids    minerals  calcium  chlorides  \\\n",
       "0             1.1  76.729301      894.94  186.639301   109.91      0.048   \n",
       "1             5.6   4.795712     1160.95  251.875712   247.08      0.039   \n",
       "2             1.5  85.193710      789.82  304.703710   219.51      0.035   \n",
       "3            17.5  11.976525      777.86  237.586525   225.61      0.045   \n",
       "4             6.9   5.599673      785.72   95.399673    89.80      0.041   \n",
       "5             1.3  22.403749     1044.95  289.523749   267.12      0.057   \n",
       "6             2.5  23.875866      888.61  133.545866   109.67      0.047   \n",
       "7             5.7  23.309699     1381.79  266.529699   243.22      0.052   \n",
       "8             4.7  49.165745     1456.41  269.915745   220.75      0.046   \n",
       "9             8.9  54.450579      929.44  377.690579   323.24      0.036   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 21.0                  98.0  0.99290  3.19       0.48   \n",
       "1                 15.0                  68.0  0.99163  2.96       0.52   \n",
       "2                 45.0                 123.0  0.98949  3.24       0.36   \n",
       "3                 48.0                 253.0  1.00014  3.02       0.56   \n",
       "4                 62.0                 150.0  0.99508  3.23       0.37   \n",
       "5                 25.0                 173.0  0.99480  3.26       0.51   \n",
       "6                 20.0                 130.0  0.99178  3.15       0.48   \n",
       "7                 56.0                 152.0  0.99398  3.16       0.88   \n",
       "8                 57.0                 161.0  0.99460  3.32       0.66   \n",
       "9                  8.0                 117.0  0.99350  3.06       0.38   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.2        5  \n",
       "1     11.1        6  \n",
       "2     12.6        7  \n",
       "3      9.1        6  \n",
       "4     10.0        6  \n",
       "5      9.1        6  \n",
       "6     11.1        5  \n",
       "7     10.5        6  \n",
       "8     10.5        6  \n",
       "9     12.0        2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#1. load environment variables and data\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "#add working directory to sys path to execute utils/dataset.py\n",
    "working_dir = os.environ.get(\"WORKING_DIRECTORY\")\n",
    "sys.path.insert(0, working_dir)\n",
    "from utils.dataset import get_data \n",
    "df = get_data()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.dropna()\n",
    "#delete all data from df where quality > 10\n",
    "df = df[df[\"quality\"] <= 10]\n",
    "#onehot encode column \"wine type\"\n",
    "df = pd.get_dummies(df, columns=[\"wine type\"])\n",
    "\n",
    "X = df.drop(columns=[\"quality\"])\n",
    "y = df[\"quality\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pipeline and standard scaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import LinearRegression and DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        \"name\": \"LinearRegression\",\n",
    "        \"estimator\": LinearRegression(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"model__fit_intercept\": [True, False],\n",
    "                \"model__copy_X\": [True, False],\n",
    "                \"model__n_jobs\": [1,5,10,20],\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DecisionTreeRegressor\",\n",
    "        \"estimator\": DecisionTreeRegressor(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"model__criterion\": [\"squared_error\"],\n",
    "                \"model__splitter\": [\"best\", \"random\"],\n",
    "                \"model__max_depth\": [None, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5, 10]\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RandomForestRegressor\",\n",
    "        \"estimator\": RandomForestRegressor(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200],\n",
    "                \"model__criterion\": [\"squared_error\"],\n",
    "                \"model__max_depth\": [None, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5, 10]\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Gradient Boosting Regressor\",\n",
    "        \"estimator\": GradientBoostingRegressor(),\n",
    "        \"hyperparameters\":\n",
    "        {\n",
    "                \"model__n_estimators\": [100, 200, 500],\n",
    "                \"model__max_depth\": [None, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__learning_rate\": [0.01, 0.011, 0.012],\n",
    "                \"model__loss\": \"squared_error\",\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Support Vector Machine\",\n",
    "        \"estimator\": svm.SVR(),\n",
    "        \"hyperparameters\":\n",
    "        {\n",
    "            \"model__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "            \"model__degree\": [1, 2, 3, 4, 5],\n",
    "            \"model__gamma\": [\"scale\", \"auto\"],\n",
    "            \"model__C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"model__epsilon\": [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        \"name\": \"Gradient Boosting Regressor\",\n",
    "        \"estimator\": GradientBoostingRegressor(),\n",
    "        \"hyperparameters\":\n",
    "        {\n",
    "                \"model__n_estimators\": [100, 200, 500],\n",
    "                \"model__max_depth\": [None, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__learning_rate\": [0.01, 0.011, 0.012],\n",
    "                \"model__loss\": [\"squared_error\"],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Support Vector Machine\",\n",
    "        \"estimator\": svm.SVR(),\n",
    "        \"hyperparameters\":\n",
    "        {\n",
    "            \"model__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "            \"model__degree\": [1, 2, 3, 4, 5],\n",
    "            \"model__gamma\": [\"scale\", \"auto\"],\n",
    "            \"model__C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"model__epsilon\": [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    }}\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    print(model[\"name\"])\n",
    "    print(\"-\"*len(model[\"name\"]))\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", model[\"estimator\"])\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(pipeline, model[\"hyperparameters\"], cv=2)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\")\n",
    "    print(grid.best_params_)\n",
    "    print(\"\")\n",
    "\n",
    "    model[\"best_params\"] = grid.best_params_\n",
    "    model[\"best_score\"] = grid.best_score_\n",
    "    model[\"best_estimator\"] = grid.best_estimator_\n",
    "    model[\"best_model\"] = grid.best_estimator_.named_steps[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "models_to_save = []\n",
    "for model in models:\n",
    "    m = {\n",
    "        \"name\": model[\"name\"],\n",
    "        \"best_params\": model[\"best_params\"],\n",
    "        \"best_score\": model[\"best_score\"],\n",
    "    }\n",
    "    models_to_save.append(m)\n",
    "\n",
    "with open(\"best_models.json\", \"w\") as f:\n",
    "    json.dump(models_to_save, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_models(file: str = \"best_models.json\"):\n",
    "    try:\n",
    "        with open(file, \"r\") as f:\n",
    "            best_models = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file} not found\")\n",
    "        return None\n",
    "    \n",
    "    for model in best_models:\n",
    "        if model[\"name\"] == \"LinearRegression\":\n",
    "            model[\"estimator\"] = LinearRegression()\n",
    "        elif model[\"name\"] == \"DecisionTreeRegressor\":\n",
    "            model[\"estimator\"] = DecisionTreeRegressor()\n",
    "        elif model[\"name\"] == \"RandomForestRegressor\":\n",
    "            model[\"estimator\"] = RandomForestRegressor()\n",
    "        elif model[\"name\"] == \"Gradient Boosting Regressor\":\n",
    "            model[\"estimator\"] = GradientBoostingRegressor()\n",
    "        elif model[\"name\"] == \"Support Vector Machine\":\n",
    "            model[\"estimator\"] = svm.SVR()\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model['name']} not found\")\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5658985686532998"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = load_best_models()\n",
    "best_models[0][\"estimator\"].fit(X_train, y_train)\n",
    "best_models[0][\"estimator\"].score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
