{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# God Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading data from wines: 8000it [00:00, 22563.27it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine type</th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>minerals</th>\n",
              "      <th>calcium</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pinot noir</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.49</td>\n",
              "      <td>1.1</td>\n",
              "      <td>76.729301</td>\n",
              "      <td>894.94</td>\n",
              "      <td>186.639301</td>\n",
              "      <td>109.91</td>\n",
              "      <td>0.048</td>\n",
              "      <td>21.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.99290</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.48</td>\n",
              "      <td>9.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Merlot</td>\n",
              "      <td>6.6</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.32</td>\n",
              "      <td>5.6</td>\n",
              "      <td>4.795712</td>\n",
              "      <td>1160.95</td>\n",
              "      <td>251.875712</td>\n",
              "      <td>247.08</td>\n",
              "      <td>0.039</td>\n",
              "      <td>15.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.99163</td>\n",
              "      <td>2.96</td>\n",
              "      <td>0.52</td>\n",
              "      <td>11.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chardonnay</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.5</td>\n",
              "      <td>85.193710</td>\n",
              "      <td>789.82</td>\n",
              "      <td>304.703710</td>\n",
              "      <td>219.51</td>\n",
              "      <td>0.035</td>\n",
              "      <td>45.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>0.98949</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.36</td>\n",
              "      <td>12.6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Merlot</td>\n",
              "      <td>8.3</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.27</td>\n",
              "      <td>17.5</td>\n",
              "      <td>11.976525</td>\n",
              "      <td>777.86</td>\n",
              "      <td>237.586525</td>\n",
              "      <td>225.61</td>\n",
              "      <td>0.045</td>\n",
              "      <td>48.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>1.00014</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Merlot</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.19</td>\n",
              "      <td>6.9</td>\n",
              "      <td>5.599673</td>\n",
              "      <td>785.72</td>\n",
              "      <td>95.399673</td>\n",
              "      <td>89.80</td>\n",
              "      <td>0.041</td>\n",
              "      <td>62.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.99508</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.37</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Merlot</td>\n",
              "      <td>7.3</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>22.403749</td>\n",
              "      <td>1044.95</td>\n",
              "      <td>289.523749</td>\n",
              "      <td>267.12</td>\n",
              "      <td>0.057</td>\n",
              "      <td>25.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>0.99480</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.51</td>\n",
              "      <td>9.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Merlot</td>\n",
              "      <td>7.6</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.49</td>\n",
              "      <td>2.5</td>\n",
              "      <td>23.875866</td>\n",
              "      <td>888.61</td>\n",
              "      <td>133.545866</td>\n",
              "      <td>109.67</td>\n",
              "      <td>0.047</td>\n",
              "      <td>20.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>0.99178</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.48</td>\n",
              "      <td>11.1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Chardonnay</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.40</td>\n",
              "      <td>5.7</td>\n",
              "      <td>23.309699</td>\n",
              "      <td>1381.79</td>\n",
              "      <td>266.529699</td>\n",
              "      <td>243.22</td>\n",
              "      <td>0.052</td>\n",
              "      <td>56.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.99398</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.88</td>\n",
              "      <td>10.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Cabernet Sauvignon</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>4.7</td>\n",
              "      <td>49.165745</td>\n",
              "      <td>1456.41</td>\n",
              "      <td>269.915745</td>\n",
              "      <td>220.75</td>\n",
              "      <td>0.046</td>\n",
              "      <td>57.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>0.99460</td>\n",
              "      <td>3.32</td>\n",
              "      <td>0.66</td>\n",
              "      <td>10.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Gamay</td>\n",
              "      <td>7.7</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.39</td>\n",
              "      <td>8.9</td>\n",
              "      <td>54.450579</td>\n",
              "      <td>929.44</td>\n",
              "      <td>377.690579</td>\n",
              "      <td>323.24</td>\n",
              "      <td>0.036</td>\n",
              "      <td>8.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.99350</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            wine type  fixed acidity  volatile acidity  citric acid  \\\n",
              "0          Pinot noir            5.8              0.15         0.49   \n",
              "1              Merlot            6.6              0.25         0.32   \n",
              "2          Chardonnay            6.7              0.21         0.34   \n",
              "3              Merlot            8.3              0.28         0.27   \n",
              "4              Merlot            7.5              0.42         0.19   \n",
              "5              Merlot            7.3              0.34         0.30   \n",
              "6              Merlot            7.6              0.21         0.49   \n",
              "7          Chardonnay            6.0              0.25         0.40   \n",
              "8  Cabernet Sauvignon            6.7              0.18         0.19   \n",
              "9               Gamay            7.7              0.28         0.39   \n",
              "\n",
              "   residual sugar  magnesium  flavanoids    minerals  calcium  chlorides  \\\n",
              "0             1.1  76.729301      894.94  186.639301   109.91      0.048   \n",
              "1             5.6   4.795712     1160.95  251.875712   247.08      0.039   \n",
              "2             1.5  85.193710      789.82  304.703710   219.51      0.035   \n",
              "3            17.5  11.976525      777.86  237.586525   225.61      0.045   \n",
              "4             6.9   5.599673      785.72   95.399673    89.80      0.041   \n",
              "5             1.3  22.403749     1044.95  289.523749   267.12      0.057   \n",
              "6             2.5  23.875866      888.61  133.545866   109.67      0.047   \n",
              "7             5.7  23.309699     1381.79  266.529699   243.22      0.052   \n",
              "8             4.7  49.165745     1456.41  269.915745   220.75      0.046   \n",
              "9             8.9  54.450579      929.44  377.690579   323.24      0.036   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 21.0                  98.0  0.99290  3.19       0.48   \n",
              "1                 15.0                  68.0  0.99163  2.96       0.52   \n",
              "2                 45.0                 123.0  0.98949  3.24       0.36   \n",
              "3                 48.0                 253.0  1.00014  3.02       0.56   \n",
              "4                 62.0                 150.0  0.99508  3.23       0.37   \n",
              "5                 25.0                 173.0  0.99480  3.26       0.51   \n",
              "6                 20.0                 130.0  0.99178  3.15       0.48   \n",
              "7                 56.0                 152.0  0.99398  3.16       0.88   \n",
              "8                 57.0                 161.0  0.99460  3.32       0.66   \n",
              "9                  8.0                 117.0  0.99350  3.06       0.38   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      9.2        5  \n",
              "1     11.1        6  \n",
              "2     12.6        7  \n",
              "3      9.1        6  \n",
              "4     10.0        6  \n",
              "5      9.1        6  \n",
              "6     11.1        5  \n",
              "7     10.5        6  \n",
              "8     10.5        6  \n",
              "9     12.0        2  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#1. load environment variables and data\n",
        "\n",
        "# load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "#add working directory to sys path to execute utils/dataset.py\n",
        "working_dir = os.environ.get(\"WORKING_DIRECTORY\")\n",
        "sys.path.insert(0, working_dir)\n",
        "\n",
        "from utils.dataset import get_data \n",
        "\n",
        "from utils.pipeline_moduls import fs_colinearity, fs_vif, outlier_label, outlier_num, dim_reduction\n",
        "\n",
        "df = get_data()\n",
        "\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_features = df.select_dtypes(include=['object']).columns\n",
        "numerical_features = df.select_dtypes(include=[np.number]).columns\n",
        "#drop 'quality' from numerical features (its a series)\n",
        "numerical_features = numerical_features.drop('quality')\n",
        "label = pd.Series('quality')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning Pipeline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modules"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Label Outlier Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:343: UserWarning: With transform=\"pandas\", `func` should return a DataFrame to follow the set_output API.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "outlier_detection_label = FunctionTransformer(outlier_label).set_output(transform=\"pandas\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Feature Outlier Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "outlier_detection = FunctionTransformer(outlier_num).set_output(transform=\"pandas\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def feature_selection(df,colinearity_threshold=0.5, correlation_threshold=0.1, vif_threshold=5):\n",
        "    dropped_features = []\n",
        "    dropped_features_set = set(dropped_features)\n",
        "\n",
        "    # Add elements from fs_colinearity to dropped_features_set\n",
        "    dropped_features_set.update(fs_colinearity(df, colinearity_threshold, correlation_threshold))\n",
        "\n",
        "    # Add elements from fs_vif to dropped_features_set\n",
        "    dropped_features_set.update(fs_vif(df, correlation_threshold, vif_threshold))\n",
        "\n",
        "    # Convert dropped_features_set back to a list\n",
        "    dropped_features = list(dropped_features_set)\n",
        "    print(\"Dropping Features: \", dropped_features)\n",
        "    # Drop the features in dropped_features from the DataFrame\n",
        "    df = df.drop(columns=dropped_features)\n",
        "\n",
        "    # Save dropped features list to a JSON file\n",
        "    with open('dropped_features.json', 'w') as f:\n",
        "        json.dump(dropped_features, f)\n",
        "    return df\n",
        "feature_selection = FunctionTransformer(feature_selection).set_output(transform=\"pandas\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleaning_pipeline = Pipeline(steps=[\n",
        "])\n",
        "\n",
        "cleaning_pipeline_scaled = Pipeline(steps=[\n",
        "])\n",
        "\n",
        "scaler_minmax = MinMaxScaler()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sub-Pipeline: Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_imputer = SimpleImputer(strategy=\"most_frequent\").set_output(transform=\"pandas\")\n",
        "\n",
        "#pipeline for categorical features\n",
        "categorical_pipeline = Pipeline(steps=[])\n",
        "categorical_pipeline.steps.append(('imputer', categorical_imputer))\n",
        "categorical_pipeline.steps.append(('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform=\"pandas\")))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sub-Pipeline: Numerical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pipeline for numerical features\n",
        "numeric_pipeline = Pipeline(steps=[])\n",
        "numerical_imputer = SimpleImputer(strategy=\"mean\").set_output(transform=\"pandas\")\n",
        "\n",
        "numeric_pipeline.steps.append(('imputer', numerical_imputer))\n",
        "numeric_pipeline.steps.append(('outlier_detection', outlier_detection))\n",
        "\n",
        "#pipeline_scaled for numerical features\n",
        "numeric_pipeline_scaled = Pipeline(steps=[])\n",
        "\n",
        "numeric_pipeline_scaled.steps.append(('imputer', numerical_imputer))\n",
        "numeric_pipeline_scaled.steps.append(('outlier_detection', outlier_detection))\n",
        "numeric_pipeline_scaled.steps.append(('scaler', scaler_minmax))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sub-Pipeline: Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pipeline for label\n",
        "label_pipeline = Pipeline(steps=[])\n",
        "label_pipeline.steps.append(('imputer', numerical_imputer))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;outlier_detection&#x27;,\n",
              "                                                                   FunctionTransformer(func=&lt;function outlier_num at 0x000001E53BDCB2E0&gt;)),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   MinMaxScaler())]),\n",
              "                                                  Index([&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;,\n",
              "       &#x27;magnesium&#x27;, &#x27;flavanoids&#x27;, &#x27;minerals&#x27;, &#x27;calcium&#x27;, &#x27;c...\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  Index([&#x27;wine type&#x27;], dtype=&#x27;object&#x27;)),\n",
              "                                                 (&#x27;label&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer())]),\n",
              "                                                  0    quality\n",
              "dtype: object)])),\n",
              "                (&#x27;outlier_detection_label&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function outlier_label at 0x000001E53BDCB250&gt;)),\n",
              "                (&#x27;feature_selection&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function feature_selection at 0x000001E53BDF24D0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;outlier_detection&#x27;,\n",
              "                                                                   FunctionTransformer(func=&lt;function outlier_num at 0x000001E53BDCB2E0&gt;)),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   MinMaxScaler())]),\n",
              "                                                  Index([&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;,\n",
              "       &#x27;magnesium&#x27;, &#x27;flavanoids&#x27;, &#x27;minerals&#x27;, &#x27;calcium&#x27;, &#x27;c...\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  Index([&#x27;wine type&#x27;], dtype=&#x27;object&#x27;)),\n",
              "                                                 (&#x27;label&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer())]),\n",
              "                                                  0    quality\n",
              "dtype: object)])),\n",
              "                (&#x27;outlier_detection_label&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function outlier_label at 0x000001E53BDCB250&gt;)),\n",
              "                (&#x27;feature_selection&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function feature_selection at 0x000001E53BDF24D0&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
              "                                                 (&#x27;outlier_detection&#x27;,\n",
              "                                                  FunctionTransformer(func=&lt;function outlier_num at 0x000001E53BDCB2E0&gt;)),\n",
              "                                                 (&#x27;scaler&#x27;, MinMaxScaler())]),\n",
              "                                 Index([&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;,\n",
              "       &#x27;magnesium&#x27;, &#x27;flavanoids&#x27;, &#x27;minerals&#x27;, &#x27;calcium&#x27;, &#x27;chlorides&#x27;,\n",
              "       &#x27;free sulfur dioxide&#x27;, &#x27;total sulfur dioxide&#x27;, &#x27;density&#x27;, &#x27;pH&#x27;,\n",
              "       &#x27;sulphates&#x27;, &#x27;alcohol&#x27;],\n",
              "      dtype=&#x27;object&#x27;)),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;onehot&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                sparse_output=False))]),\n",
              "                                 Index([&#x27;wine type&#x27;], dtype=&#x27;object&#x27;)),\n",
              "                                (&#x27;label&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())]),\n",
              "                                 0    quality\n",
              "dtype: object)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;,\n",
              "       &#x27;magnesium&#x27;, &#x27;flavanoids&#x27;, &#x27;minerals&#x27;, &#x27;calcium&#x27;, &#x27;chlorides&#x27;,\n",
              "       &#x27;free sulfur dioxide&#x27;, &#x27;total sulfur dioxide&#x27;, &#x27;density&#x27;, &#x27;pH&#x27;,\n",
              "       &#x27;sulphates&#x27;, &#x27;alcohol&#x27;],\n",
              "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function outlier_num at 0x000001E53BDCB2E0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;wine type&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">label</label><div class=\"sk-toggleable__content\"><pre>0    quality\n",
              "dtype: object</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function outlier_label at 0x000001E53BDCB250&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function feature_selection at 0x000001E53BDF24D0&gt;)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('outlier_detection',\n",
              "                                                                   FunctionTransformer(func=<function outlier_num at 0x000001E53BDCB2E0>)),\n",
              "                                                                  ('scaler',\n",
              "                                                                   MinMaxScaler())]),\n",
              "                                                  Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
              "       'magnesium', 'flavanoids', 'minerals', 'calcium', 'c...\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  Index(['wine type'], dtype='object')),\n",
              "                                                 ('label',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer())]),\n",
              "                                                  0    quality\n",
              "dtype: object)])),\n",
              "                ('outlier_detection_label',\n",
              "                 FunctionTransformer(func=<function outlier_label at 0x000001E53BDCB250>)),\n",
              "                ('feature_selection',\n",
              "                 FunctionTransformer(func=<function feature_selection at 0x000001E53BDF24D0>))])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_pipeline, numerical_features),\n",
        "        ('cat', categorical_pipeline, categorical_features),\n",
        "        ('label', label_pipeline, label)\n",
        "    ]).set_output(transform=\"pandas\")\n",
        "cleaning_pipeline.steps.append(('preprocessor', preprocessor))\n",
        "cleaning_pipeline.steps.append((\"outlier_detection_label\", outlier_detection_label))\n",
        "cleaning_pipeline.steps.append(('feature_selection', feature_selection))\n",
        "#cleaning_pipeline\n",
        "\n",
        "preprocessor_scaled = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_pipeline_scaled, numerical_features),\n",
        "        ('cat', categorical_pipeline, categorical_features),\n",
        "        ('label', label_pipeline, label)\n",
        "    ]).set_output(transform=\"pandas\")\n",
        "cleaning_pipeline_scaled.steps.append(('preprocessor', preprocessor_scaled))\n",
        "cleaning_pipeline_scaled.steps.append((\"outlier_detection_label\", outlier_detection_label))\n",
        "cleaning_pipeline_scaled.steps.append(('feature_selection', feature_selection))\n",
        "cleaning_pipeline_scaled"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "models = [\n",
        "    {\n",
        "        \"name\": \"LinearRegression\",\n",
        "        \"estimator\": LinearRegression(),\n",
        "        \"hyperparameters\":\n",
        "            {\n",
        "                \"fit_intercept\": [True, False],\n",
        "                \"copy_X\": [True, False]\n",
        "            },\n",
        "        \"scalable\": 0\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"DecisionTreeRegressor\",\n",
        "        \"estimator\": DecisionTreeRegressor(),\n",
        "        \"hyperparameters\":\n",
        "            {\n",
        "                \"criterion\": [\"squared_error\", \"friedman_mse\"],\n",
        "                \"splitter\": [\"best\", \"random\"],\n",
        "                \"max_depth\": [None, 2, 5, 10],\n",
        "                \"min_samples_split\": [2, 5, 10],\n",
        "                \"min_samples_leaf\": [1, 5, 10]\n",
        "            },\n",
        "        \"scalable\": 0\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"RandomForestRegressor\",\n",
        "        \"estimator\": RandomForestRegressor(),\n",
        "        \"hyperparameters\":\n",
        "            {\n",
        "                \"n_estimators\": [100, 200],\n",
        "                \"criterion\": [\"squared_error\", \"friedman_mse\"],\n",
        "                \"max_depth\": [None, 2, 5, 10],\n",
        "                \"min_samples_split\": [2, 5, 10],\n",
        "                \"min_samples_leaf\": [1, 5, 10]\n",
        "            },\n",
        "        \"scalable\": 0\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Gradient Boosting Regressor\",\n",
        "        \"estimator\": GradientBoostingRegressor(),\n",
        "        \"hyperparameters\":\n",
        "        {       \n",
        "                \"n_estimators\": [100, 200, 500],\n",
        "                \"max_depth\": [None, 3, 5, 10],\n",
        "                \"min_samples_split\": [2, 5, 10],\n",
        "                \"learning_rate\": [0.1, 0.05, 0.001],\n",
        "                \"loss\": ['squared_error', 'absolute_error', 'huber'],\n",
        "        },\n",
        "        \"scalable\": 0\n",
        "    }, \n",
        "     {\n",
        "        \"name\": \"Support Vector Machine\",\n",
        "        \"estimator\": SVR(),\n",
        "        \"hyperparameters\": {\n",
        "            \"C\": [1, 10, 100],\n",
        "            \"kernel\": [\"rbf\", \"linear\", \"poly\"]\n",
        "        },\n",
        "        \"best_score\": 0.5567442927702857,\n",
        "        \"scalable\": 1\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"ANN\",\n",
        "        \"estimator\": MLPRegressor(),\n",
        "        \"hyperparameters\": {\n",
        "            'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "            'alpha': [0.0001, 0.001, 0.01],\n",
        "            'hidden_layer_sizes': [(100, ),(100, 50), (100, 50, 25), (100, 75, 50, 25)],\n",
        "            'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "            'solver': ['adam', 'lbfgs']\n",
        "        },\n",
        "        \"best_score\": 0.5567442927702857,\n",
        "        \"scalable\": 1\n",
        "    }, \n",
        "    {\n",
        "        \"name\": \"KNN\",\n",
        "        \"estimator\": KNeighborsRegressor(),\n",
        "        \"hyperparameters\": {\n",
        "            'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
        "            'weights' : ['uniform', 'distance']\n",
        "        },\n",
        "        \"best_score\": 0.5567442927702857,\n",
        "        \"scalable\": 1\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pickle\n",
        "\n",
        "\n",
        "best_models = []\n",
        "\n",
        "def god_function(dirty_df):\n",
        "    for model in models:\n",
        "        print(model[\"name\"])\n",
        "        print(\"-\"*len(model[\"name\"]))\n",
        "        if model[\"scalable\"] is not None:\n",
        "            if model[\"scalable\"] == 0:\n",
        "                clean_df = pd.DataFrame(cleaning_pipeline.fit_transform(dirty_df))\n",
        "            if model[\"scalable\"] == 1:\n",
        "                clean_df = pd.DataFrame(cleaning_pipeline_scaled.fit_transform(dirty_df))\n",
        "        X = clean_df.drop('label__quality', axis=1)\n",
        "        y = clean_df['label__quality']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "        grid = GridSearchCV(model[\"estimator\"], model[\"hyperparameters\"], cv=10, n_jobs=-1)\n",
        "        grid = grid.fit(X_train, y_train)\n",
        "        print(\"Best Parameters:\")\n",
        "        print(grid.best_params_)\n",
        "        print(\"\")\n",
        "        print(\"Best Score:\", grid.best_score_, \"\\t\", \"Test Score:\", grid.score(X_test, y_test))\n",
        "        print(\"Fit Time:\", grid.refit_time_)\n",
        "        print(\"\")\n",
        "        m = {\n",
        "            \"name\": model[\"name\"],\n",
        "            \"best_params\": grid.best_params_,\n",
        "            \"best_score\": grid.best_score_,\n",
        "            \"fit_time\": grid.refit_time_,\n",
        "            \"test_score\":  grid.score(X_test, y_test)\n",
        "        }\n",
        "        best_models.append(m)\n",
        "        \n",
        "        #save best models to json\n",
        "        with open(\"./models/best_models.json\", \"w\") as f:\n",
        "            json.dump(best_models, f, indent=4)\n",
        "            \n",
        "        #save best estimator from grid with pickle\n",
        "        with open(\"./models/\" + model[\"name\"] + '.pkl', 'wb') as f:\n",
        "            pickle.dump(grid.best_estimator_, f)\n",
        "\n",
        "god_function(df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training with 7000 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LinearRegression\n",
            "----------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping Features:  ['num__free sulfur dioxide', 'num__calcium', 'num__minerals', 'cat__wine type_Pinot noir', 'num__residual sugar']\n",
            "Best Parameters:\n",
            "{'copy_X': True, 'fit_intercept': True}\n",
            "\n",
            "Best Score: 0.5327285592690533 \t Test Score: 0.5375349921589769\n",
            "Fit Time: 0.009988546371459961\n",
            "\n",
            "DecisionTreeRegressor\n",
            "---------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping Features:  ['num__free sulfur dioxide', 'num__calcium', 'num__minerals', 'cat__wine type_Pinot noir', 'num__residual sugar']\n",
            "Best Parameters:\n",
            "{'criterion': 'squared_error', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "\n",
            "Best Score: 0.7073883989242278 \t Test Score: 0.7744701384175121\n",
            "Fit Time: 0.07996821403503418\n",
            "\n",
            "RandomForestRegressor\n",
            "---------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping Features:  ['num__free sulfur dioxide', 'num__calcium', 'num__minerals', 'cat__wine type_Pinot noir', 'num__residual sugar']\n",
            "Best Parameters:\n",
            "{'criterion': 'friedman_mse', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "\n",
            "Best Score: 0.8172918706792054 \t Test Score: 0.8486744346798154\n",
            "Fit Time: 13.01500129699707\n",
            "\n",
            "Gradient Boosting Regressor\n",
            "---------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping Features:  ['num__free sulfur dioxide', 'num__calcium', 'num__minerals', 'cat__wine type_Pinot noir', 'num__residual sugar']\n",
            "Best Parameters:\n",
            "{'learning_rate': 0.05, 'loss': 'absolute_error', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 500}\n",
            "\n",
            "Best Score: 0.848391925827347 \t Test Score: 0.8800458159047987\n",
            "Fit Time: 198.70731782913208\n",
            "\n",
            "Support Vector Machine\n",
            "----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping Features:  ['num__free sulfur dioxide', 'num__calcium', 'num__minerals', 'cat__wine type_Pinot noir', 'num__residual sugar']\n",
            "Best Parameters:\n",
            "{'C': 100, 'kernel': 'rbf'}\n",
            "\n",
            "Best Score: 0.6261900880869085 \t Test Score: 0.6410895596826263\n",
            "Fit Time: 38.09536671638489\n",
            "\n",
            "ANN\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping Features:  ['num__free sulfur dioxide', 'num__calcium', 'num__minerals', 'cat__wine type_Pinot noir', 'num__residual sugar']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 75, 50, 25), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "\n",
            "Best Score: 0.6141883495943115 \t Test Score: 0.6303336825710211\n",
            "Fit Time: 43.284379959106445\n",
            "\n",
            "KNN\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KevinEberhardtT4MEDI\\Desktop\\data-science\\data-science\\venv\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping Features:  ['num__free sulfur dioxide', 'num__calcium', 'num__minerals', 'cat__wine type_Pinot noir', 'num__residual sugar']\n",
            "Best Parameters:\n",
            "{'n_neighbors': 15, 'weights': 'distance'}\n",
            "\n",
            "Best Score: 0.7970711096671389 \t Test Score: 0.8511037942759834\n",
            "Fit Time: 0.033989667892456055\n",
            "\n",
            "Saving best models to json… Done\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "best_models = []\n",
        "def god_function_goes_server(dirty_df):\n",
        "    df_validation = dirty_df.sample(n=1000, random_state=42)\n",
        "    dirty_df = dirty_df.drop(df_validation.index)\n",
        "    for model in models:\n",
        "        print(model[\"name\"])\n",
        "        print(\"-\"*len(model[\"name\"]))\n",
        "        if model[\"scalable\"] is not None:\n",
        "            if model[\"scalable\"] == 0:\n",
        "                clean_df = pd.DataFrame(cleaning_pipeline.fit_transform(dirty_df))\n",
        "            if model[\"scalable\"] == 1:\n",
        "                clean_df = pd.DataFrame(cleaning_pipeline_scaled.fit_transform(dirty_df))\n",
        "        X = clean_df.drop('label__quality', axis=1)\n",
        "        y = clean_df['label__quality']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "        grid = GridSearchCV(model[\"estimator\"], model[\"hyperparameters\"], cv=5, n_jobs=-1)\n",
        "        grid = grid.fit(X_train, y_train)\n",
        "        print(\"Best Parameters:\")\n",
        "        print(grid.best_params_)\n",
        "        print(\"\")\n",
        "        print(\"Best Score:\", grid.best_score_, \"\\t\", \"Test Score:\", grid.score(X_test, y_test))\n",
        "        print(\"Fit Time:\", grid.refit_time_)\n",
        "        print(\"\")\n",
        "        m = {\n",
        "            \"name\": model[\"name\"],\n",
        "            \"best_params\": grid.best_params_,\n",
        "            \"best_score\": grid.best_score_,\n",
        "            \"fit_time\": grid.refit_time_,\n",
        "        }\n",
        "        best_models.append(m)\n",
        "        \n",
        "        #save best estimator from grid with pickle\n",
        "        with open(\"./models/7000_samples/\" + model[\"name\"] + '.pkl', 'wb') as f:\n",
        "            pickle.dump(grid.best_estimator_, f)\n",
        "    \n",
        "    #save best models to json\n",
        "    print(\"Saving best models to json…\", end=\" \")\n",
        "    with open(\"./models/best_models_7000_samples.json\", \"w\") as f:\n",
        "        json.dump(best_models, f, indent=4)\n",
        "    print(\"Done\")\n",
        "\n",
        "god_function_goes_server(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.24.3\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_significant_features(X, y, model):\n",
        "    coefficients = model.coef_\n",
        "    intercept = model.intercept_\n",
        "\n",
        "\n",
        "    residuals = y - model.predict(X)\n",
        "\n",
        "    n = len(y)\n",
        "    p = X.shape[1]\n",
        "    df = n - p - 1\n",
        "\n",
        "    mse = np.sum(residuals ** 2) / df\n",
        "    variance_covariance_matrix = mse * np.linalg.inv(np.dot(X.T, X))\n",
        "    standard_errors = np.sqrt(np.diagonal(variance_covariance_matrix))\n",
        "\n",
        "\n",
        "    t_values = coefficients / standard_errors\n",
        "    p_values = 2 * (1 - stats.t.cdf(np.abs(t_values), df))\n",
        "\n",
        "    headers = ['Feature', 'Coefficient', 'Standard Error', 't-value', 'p-value']\n",
        "\n",
        "    prediction_metrics = pd.DataFrame(columns=headers)\n",
        "    for i in range(len(coefficients)):\n",
        "        prediction_metrics.loc[i] = [X.columns.values[i], coefficients[i], standard_errors[i], t_values[i], p_values[i]]\n",
        "\n",
        "    #remove rows with p-value > 0.05\n",
        "    features_to_remove = prediction_metrics[prediction_metrics['p-value'] > 0.05]['Feature'].values\n",
        "    print(\"Removing features: \", features_to_remove)\n",
        "    prediction_metrics = prediction_metrics[prediction_metrics['p-value'] < 0.05]\n",
        "    return prediction_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_models = [{\n",
        "        \"name\": \"LinearRegression\",\n",
        "        \"estimator\": LinearRegression(),\n",
        "        \"hyperparameters\":\n",
        "            {\n",
        "                \"fit_intercept\": [True, False],\n",
        "                \"copy_X\": [True, False],\n",
        "                \"n_jobs\": [-1]\n",
        "            }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Support Vector Machine\",\n",
        "        \"estimator\": SVR(),\n",
        "        \"hyperparameters\":\n",
        "        {\n",
        "            \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
        "            \"degree\": [1, 2, 3, 4, 5],\n",
        "            \"gamma\": [\"scale\", \"auto\"],\n",
        "            \"C\": [0.1, 1, 10, 100, 1000],\n",
        "            \"epsilon\": [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "    }\n",
        "    }\n",
        "    ]\n",
        "dirty_df = df.copy(deep=True)\n",
        "for model in test_models:\n",
        "    print(model[\"name\"])\n",
        "    print(\"-\"*len(model[\"name\"]))\n",
        "    pipeline = cleaning_pipeline\n",
        "    #pipeline.steps.pop(2)\n",
        "    clean_df = pd.DataFrame(pipeline.fit_transform(dirty_df))\n",
        "    X = clean_df.drop('label__quality', axis=1)\n",
        "    y = clean_df['label__quality']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "    grid = GridSearchCV(model[\"estimator\"], model[\"hyperparameters\"], cv=5, n_jobs=-1)\n",
        "    grid = grid.fit(X_train, y_train)\n",
        "    print(\"Best Parameters:\")\n",
        "    print(grid.best_params_)\n",
        "    print(\"\")\n",
        "    print(\"Best Score:\", grid.best_score_, \"\\t\", \"Test Score:\", grid.score(X_test, y_test))\n",
        "    print(\"Fit Time:\", grid.refit_time_)\n",
        "    print(\"\")\n",
        "    best_model = grid.best_estimator_\n",
        "    significant_features = calculate_significant_features(X_train, y_train, best_model)\n",
        "    #keep columns of X only if they are present in significant_features\n",
        "    X_train = X_train[significant_features['Feature'].values]\n",
        "    X_test = X_test[significant_features['Feature'].values]\n",
        "    grid = GridSearchCV(model[\"estimator\"], model[\"hyperparameters\"], cv=5, n_jobs=-1)\n",
        "    grid = grid.fit(X_train, y_train)\n",
        "    print(\"Best Parameters:\")\n",
        "    print(grid.best_params_)\n",
        "    print(\"\")\n",
        "    print(\"Best Score:\", grid.best_score_, \"\\t\", \"Test Score:\", grid.score(X_test, y_test))\n",
        "    print(\"Fit Time:\", grid.refit_time_)\n",
        "    print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.score()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# END TESTING"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simulation Meth-Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load best model with pickle\n",
        "best_model = pickle.load(open('best_model__random_forest.pkl','rb'))\n",
        "#select randomly 1000 data points from df and drop selected ones\n",
        "df_validation = df.sample(n=1000, random_state=1)\n",
        "clean_df = df.drop(df_validation.index)\n",
        "\n",
        "X = clean_df.drop('label__quality', axis=1)\n",
        "y = clean_df['label__quality']\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=200, stratify=y)\n",
        "\n",
        "print(best_model.score(X_validation, y_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_validation = df.sample(n=1000, random_state=42)\n",
        "\n",
        "clean_df = df.drop(df_validation.index)\n",
        "clean_df = pd.DataFrame(cleaning_pipeline.fit_transform(clean_df))\n",
        "\n",
        "X_clean = clean_df.drop('label__quality', axis=1)\n",
        "y_clean = clean_df['label__quality']\n",
        "\n",
        "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean, test_size=0.2, random_state=200, stratify=y_clean)\n",
        "best_model = RandomForestRegressor(criterion = 'squared_error', max_depth = None, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200)\n",
        "best_model = best_model.fit(X_train_clean, y_train_clean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.score(X_test_clean, y_test_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_validation = pd.DataFrame(cleaning_pipeline.fit_transform(df_validation))\n",
        "X_validation = df_validation.drop('label__quality', axis=1)\n",
        "y_validation = df_validation['label__quality']\n",
        "\n",
        "best_model.score(X_validation, y_validation)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d8ef5791812a9b011d871b4450c5904387dab1ce99926e48021d45ad42ef8d31"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
