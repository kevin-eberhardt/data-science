{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# God Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from wines: 0it [00:00, ?it/s]Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 991, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 1440, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sqlalchemy/engine/default.py\", line 657, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "MySQLdb.OperationalError: (2013, 'Lost connection to MySQL server during query')\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 991, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 1440, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sqlalchemy/engine/default.py\", line 657, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "MySQLdb.OperationalError: (2013, 'Lost connection to MySQL server during query')\n",
      "Loading data from wines: 8000it [00:00, 13876.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>minerals</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinot noir</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.1</td>\n",
       "      <td>76.729301</td>\n",
       "      <td>894.94</td>\n",
       "      <td>186.639301</td>\n",
       "      <td>109.91</td>\n",
       "      <td>0.048</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.99290</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.795712</td>\n",
       "      <td>1160.95</td>\n",
       "      <td>251.875712</td>\n",
       "      <td>247.08</td>\n",
       "      <td>0.039</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.99163</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.52</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.5</td>\n",
       "      <td>85.193710</td>\n",
       "      <td>789.82</td>\n",
       "      <td>304.703710</td>\n",
       "      <td>219.51</td>\n",
       "      <td>0.035</td>\n",
       "      <td>45.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.98949</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>17.5</td>\n",
       "      <td>11.976525</td>\n",
       "      <td>777.86</td>\n",
       "      <td>237.586525</td>\n",
       "      <td>225.61</td>\n",
       "      <td>0.045</td>\n",
       "      <td>48.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1.00014</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.19</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.599673</td>\n",
       "      <td>785.72</td>\n",
       "      <td>95.399673</td>\n",
       "      <td>89.80</td>\n",
       "      <td>0.041</td>\n",
       "      <td>62.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99508</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.37</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.3</td>\n",
       "      <td>22.403749</td>\n",
       "      <td>1044.95</td>\n",
       "      <td>289.523749</td>\n",
       "      <td>267.12</td>\n",
       "      <td>0.057</td>\n",
       "      <td>25.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.5</td>\n",
       "      <td>23.875866</td>\n",
       "      <td>888.61</td>\n",
       "      <td>133.545866</td>\n",
       "      <td>109.67</td>\n",
       "      <td>0.047</td>\n",
       "      <td>20.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99178</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.48</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.7</td>\n",
       "      <td>23.309699</td>\n",
       "      <td>1381.79</td>\n",
       "      <td>266.529699</td>\n",
       "      <td>243.22</td>\n",
       "      <td>0.052</td>\n",
       "      <td>56.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99398</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.7</td>\n",
       "      <td>49.165745</td>\n",
       "      <td>1456.41</td>\n",
       "      <td>269.915745</td>\n",
       "      <td>220.75</td>\n",
       "      <td>0.046</td>\n",
       "      <td>57.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gamay</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>8.9</td>\n",
       "      <td>54.450579</td>\n",
       "      <td>929.44</td>\n",
       "      <td>377.690579</td>\n",
       "      <td>323.24</td>\n",
       "      <td>0.036</td>\n",
       "      <td>8.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.99350</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wine type  fixed acidity  volatile acidity  citric acid  \\\n",
       "0          Pinot noir            5.8              0.15         0.49   \n",
       "1              Merlot            6.6              0.25         0.32   \n",
       "2          Chardonnay            6.7              0.21         0.34   \n",
       "3              Merlot            8.3              0.28         0.27   \n",
       "4              Merlot            7.5              0.42         0.19   \n",
       "5              Merlot            7.3              0.34         0.30   \n",
       "6              Merlot            7.6              0.21         0.49   \n",
       "7          Chardonnay            6.0              0.25         0.40   \n",
       "8  Cabernet Sauvignon            6.7              0.18         0.19   \n",
       "9               Gamay            7.7              0.28         0.39   \n",
       "\n",
       "   residual sugar  magnesium  flavanoids    minerals  calcium  chlorides  \\\n",
       "0             1.1  76.729301      894.94  186.639301   109.91      0.048   \n",
       "1             5.6   4.795712     1160.95  251.875712   247.08      0.039   \n",
       "2             1.5  85.193710      789.82  304.703710   219.51      0.035   \n",
       "3            17.5  11.976525      777.86  237.586525   225.61      0.045   \n",
       "4             6.9   5.599673      785.72   95.399673    89.80      0.041   \n",
       "5             1.3  22.403749     1044.95  289.523749   267.12      0.057   \n",
       "6             2.5  23.875866      888.61  133.545866   109.67      0.047   \n",
       "7             5.7  23.309699     1381.79  266.529699   243.22      0.052   \n",
       "8             4.7  49.165745     1456.41  269.915745   220.75      0.046   \n",
       "9             8.9  54.450579      929.44  377.690579   323.24      0.036   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 21.0                  98.0  0.99290  3.19       0.48   \n",
       "1                 15.0                  68.0  0.99163  2.96       0.52   \n",
       "2                 45.0                 123.0  0.98949  3.24       0.36   \n",
       "3                 48.0                 253.0  1.00014  3.02       0.56   \n",
       "4                 62.0                 150.0  0.99508  3.23       0.37   \n",
       "5                 25.0                 173.0  0.99480  3.26       0.51   \n",
       "6                 20.0                 130.0  0.99178  3.15       0.48   \n",
       "7                 56.0                 152.0  0.99398  3.16       0.88   \n",
       "8                 57.0                 161.0  0.99460  3.32       0.66   \n",
       "9                  8.0                 117.0  0.99350  3.06       0.38   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.2        5  \n",
       "1     11.1        6  \n",
       "2     12.6        7  \n",
       "3      9.1        6  \n",
       "4     10.0        6  \n",
       "5      9.1        6  \n",
       "6     11.1        5  \n",
       "7     10.5        6  \n",
       "8     10.5        6  \n",
       "9     12.0        2  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#1. load environment variables and data\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "#add working directory to sys path to execute utils/dataset.py\n",
    "working_dir = os.environ.get(\"WORKING_DIRECTORY\")\n",
    "sys.path.insert(0, working_dir)\n",
    "from utils.dataset import get_data \n",
    "df = get_data()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns\n",
    "#drop 'quality' from numerical features (its a series)\n",
    "numerical_features = numerical_features.drop('quality')\n",
    "label = pd.Series('quality')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## God Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#import FunctionTransformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:343: UserWarning: With transform=\"pandas\", `func` should return a DataFrame to follow the set_output API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def outlier_detection_label(df):\n",
    "    #detect outliers and impute them with the simple imputer\n",
    "    from sklearn.impute import KNNImputer\n",
    "\n",
    "    #detect outliers with z-score and set them to NaN with = np.nan\n",
    "    from scipy import stats\n",
    "    z = np.abs(stats.zscore(df.iloc[:, df.shape[1]-1]))\n",
    "    df.iloc[:, df.shape[1]-1][(z >= 3)] = np.nan\n",
    "\n",
    "\n",
    "    #impute outliers with linear regression\n",
    "    imputer = KNNImputer(n_neighbors=5).set_output(transform=\"pandas\")\n",
    "    df = imputer.fit_transform(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "outlier_detection_label = FunctionTransformer(outlier_detection_label).set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(df):\n",
    "    #detect outliers and impute them with the simple imputer\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    #detect outliers\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    #detect outliers for each column and set them to NaN\n",
    "    for col in df.columns:\n",
    "        df.loc[(df[col] < (Q1[col] - 1.5 * IQR[col])) | (df[col] > (Q3[col] + 1.5 * IQR[col])), col] = np.nan\n",
    "\n",
    "    #impute outliers with median\n",
    "    imputer = SimpleImputer(strategy='median').set_output(transform=\"pandas\")\n",
    "    df = imputer.fit_transform(df)\n",
    "\n",
    "    return df\n",
    "outlier_detection = FunctionTransformer(outlier_detection).set_output(transform=\"pandas\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:343: UserWarning: With transform=\"pandas\", `func` should return a DataFrame to follow the set_output API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "\n",
    "\n",
    "def feature_selection(df, colinearity_threshold=0.5,correlation_threshold=0.1, vif_threshold=10.0):\n",
    "    dropped_features = []  # List to store dropped features\n",
    "    #-------------------------------------------------Cleaning-------------------------------------------------\n",
    "\n",
    "    # exclude non numeric columns\n",
    "    df = df.select_dtypes(exclude=['object'])\n",
    "    \n",
    "   #-------------------------------------------------Colinearity-------------------------------------------------\n",
    "    # Calculate the correlation between columns\n",
    "    corr_matrix = df.corr().abs()\n",
    "    # Create a mask to select the upper triangle of the correlation matrix\n",
    "    mask = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "\n",
    "    # Apply the mask to get the upper triangle of the correlation matrix\n",
    "    upper_triangle = corr_matrix.where(mask)\n",
    "    \n",
    "    # Find the columns with colinearity greater than correlation_threshold\n",
    "    colinear_columns = upper_triangle[upper_triangle > colinearity_threshold].stack().index\n",
    "     # Get the values of colinearity\n",
    "    colinearity_values = upper_triangle[upper_triangle > colinearity_threshold].stack()\n",
    "\n",
    "    # loop through the colinear_columns and select the one with lower correlation to quality and avoid duplicates in the list\n",
    "    print(\"--------colinearity--------\")\n",
    "    for col1, col2 in colinear_columns:\n",
    "        corr_col1 = df[col1].corr(df['label__quality'])\n",
    "        corr_col2 = df[col2].corr(df['label__quality'])\n",
    "        print(\"High Colinearity between \" + col1 + \" and \"+col2 + \" with a value of \" + str(colinearity_values[col1, col2]))\n",
    "        if abs(corr_col1) < abs(corr_col2):\n",
    "                corr_col = df[col1].corr(df['label__quality'])\n",
    "                if abs(corr_col) < correlation_threshold:\n",
    "                    print(\"Dropping \" + col1 + \" because of low correlation \"+str(corr_col1)+\" with quality\"+ \"\\n\")\n",
    "                    df = df.drop(col1, axis=1)\n",
    "                    dropped_features.append(col1)\n",
    "                else:\n",
    "                    print(\"Not Dropping \" + col1 + \" because of high correlation \"+str(corr_col1)+\" with quality\"+ \"\\n\")\n",
    "\n",
    "        else:\n",
    "                corr_col = df[col2].corr(df['label__quality'])\n",
    "                if abs(corr_col) < correlation_threshold:\n",
    "                    print(\"Dropping \" + col2 + \" because of low correlation \"+str(corr_col)+\" with quality\"+ \"\\n\")\n",
    "                    df = df.drop(col2, axis=1)\n",
    "                    dropped_features.append(col2)\n",
    "                else: \n",
    "                    print(\"Not Dropping \" + col2 + \" because of high correlation \"+str(corr_col)+\" with quality\"+ \"\\n\")\n",
    "                     \n",
    "\n",
    "    print(\"Every colinearity is below the threshold of \"+str(colinearity_threshold)+\"! \\n\")\n",
    "    #-------------------------------------------------VIF-------------------------------------------------\n",
    "    columns_to_exclude = ['label__quality']\n",
    "    # Select the columns excluding the quality label\n",
    "    columns = [col for col in df.select_dtypes(exclude='object').columns if col not in columns_to_exclude]\n",
    "\n",
    "    # Create a new dataframe with only the selected columns\n",
    "    df_selected = df[columns]\n",
    "\n",
    "    # Add a constant column to the dataframe (required for VIF calculation)\n",
    "    df_selected = sm.add_constant(df_selected)\n",
    "\n",
    "    print(\"--------VIF--------\"+ \"\\n\")\n",
    "    vifToRemove = 0\n",
    "    while True:\n",
    "        # Calculate VIF values for remaining features\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"Variable\"] = df_selected.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(df_selected.values, i) if np.var(df_selected.iloc[:, i]) != 0 else 0 for i in range(df_selected.shape[1])]\n",
    "\n",
    "        # Exclude the constant column from the results\n",
    "        vif = vif[1:]\n",
    "        # Order the VIF values in ascending order\n",
    "        vif.sort_values('VIF', ascending=False, inplace=True)\n",
    "        # Check if all VIF values are below the threshold\n",
    "        if all(vif.iloc[vifToRemove:, vif.columns.get_loc(\"VIF\")] < vif_threshold):\n",
    "            print(\"Every VIF is below the threshold of \"+str(vif_threshold)+\"! \\n\")\n",
    "            break\n",
    "\n",
    "        # Find the feature with the highest VIF value\n",
    "        if vifToRemove < vif.shape[0] and vif.iloc[vifToRemove][\"Variable\"] is not None:\n",
    "            highest_vif_feature = vif.iloc[vifToRemove][\"Variable\"]\n",
    "        \n",
    "        # Check correlation of the highest VIF feature with quality label\n",
    "        correlation = df[highest_vif_feature].corr(df[\"label__quality\"])\n",
    "        print(\"Highest VIF Value, Feature: \" + str(highest_vif_feature) + \" with a value of \" + str(vif.iloc[vifToRemove][\"VIF\"]))\n",
    "       \n",
    "\n",
    "        if abs(correlation) < correlation_threshold:\n",
    "            # Remove the feature if correlation is below the threshold\n",
    "            print(\"Dropping \" + highest_vif_feature + \" because of low correlation \"+str(correlation)+\" with quality\"+ \"\\n\")\n",
    "            dropped_features.append(highest_vif_feature)\n",
    "            df = df.drop(highest_vif_feature, axis=1)\n",
    "            df_selected = df_selected.drop(highest_vif_feature, axis=1)  # Drop from df_selected as well\n",
    "        else:\n",
    "            print(\"Not Dropping \" + highest_vif_feature + \" because of high correlation \"+str(correlation)+\" with quality\"+ \"\\n\")\n",
    "            # Move on to the next highest VIF feature\n",
    "            vifToRemove = vifToRemove + 1\n",
    "    \n",
    "    # Save dropped features list to a JSON file\n",
    "    with open('dropped_features.json', 'w') as f:\n",
    "        json.dump(dropped_features, f)\n",
    "\n",
    "    return df\n",
    "feature_selection = FunctionTransformer(feature_selection).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-40 {color: black;background-color: white;}#sk-container-id-40 pre{padding: 0;}#sk-container-id-40 div.sk-toggleable {background-color: white;}#sk-container-id-40 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-40 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-40 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-40 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-40 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-40 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-40 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-40 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-40 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-40 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-40 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-40 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-40 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-40 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-40 div.sk-item {position: relative;z-index: 1;}#sk-container-id-40 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-40 div.sk-item::before, #sk-container-id-40 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-40 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-40 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-40 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-40 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-40 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-40 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-40 div.sk-label-container {text-align: center;}#sk-container-id-40 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-40 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-40\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;outlier_detection&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;function outlier_detection at 0x15095b240&gt;))]),\n",
       "                                                  Index([&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;,\n",
       "       &#x27;magnesium&#x27;, &#x27;flavanoids&#x27;, &#x27;minerals&#x27;, &#x27;calcium&#x27;, &#x27;chlorides&#x27;,\n",
       "       &#x27;free sulfur dioxid...\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  Index([&#x27;wine type&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;label&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  0    quality\n",
       "dtype: object)])),\n",
       "                (&#x27;outlier_detection_label&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function outlier_detection_label at 0x14f6bf100&gt;)),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function feature_selection at 0x158912020&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-358\" type=\"checkbox\" ><label for=\"sk-estimator-id-358\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;outlier_detection&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;function outlier_detection at 0x15095b240&gt;))]),\n",
       "                                                  Index([&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;,\n",
       "       &#x27;magnesium&#x27;, &#x27;flavanoids&#x27;, &#x27;minerals&#x27;, &#x27;calcium&#x27;, &#x27;chlorides&#x27;,\n",
       "       &#x27;free sulfur dioxid...\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  Index([&#x27;wine type&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;label&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  0    quality\n",
       "dtype: object)])),\n",
       "                (&#x27;outlier_detection_label&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function outlier_detection_label at 0x14f6bf100&gt;)),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function feature_selection at 0x158912020&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-359\" type=\"checkbox\" ><label for=\"sk-estimator-id-359\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;outlier_detection&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function outlier_detection at 0x15095b240&gt;))]),\n",
       "                                 Index([&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;,\n",
       "       &#x27;magnesium&#x27;, &#x27;flavanoids&#x27;, &#x27;minerals&#x27;, &#x27;calcium&#x27;, &#x27;chlorides&#x27;,\n",
       "       &#x27;free sulfur dioxide&#x27;, &#x27;total sulfur dioxide&#x27;, &#x27;density&#x27;, &#x27;pH&#x27;,\n",
       "       &#x27;sulphates&#x27;, &#x27;alcohol&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 Index([&#x27;wine type&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;label&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())]),\n",
       "                                 0    quality\n",
       "dtype: object)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-360\" type=\"checkbox\" ><label for=\"sk-estimator-id-360\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;,\n",
       "       &#x27;magnesium&#x27;, &#x27;flavanoids&#x27;, &#x27;minerals&#x27;, &#x27;calcium&#x27;, &#x27;chlorides&#x27;,\n",
       "       &#x27;free sulfur dioxide&#x27;, &#x27;total sulfur dioxide&#x27;, &#x27;density&#x27;, &#x27;pH&#x27;,\n",
       "       &#x27;sulphates&#x27;, &#x27;alcohol&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-361\" type=\"checkbox\" ><label for=\"sk-estimator-id-361\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-362\" type=\"checkbox\" ><label for=\"sk-estimator-id-362\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function outlier_detection at 0x15095b240&gt;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-363\" type=\"checkbox\" ><label for=\"sk-estimator-id-363\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;wine type&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-364\" type=\"checkbox\" ><label for=\"sk-estimator-id-364\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-365\" type=\"checkbox\" ><label for=\"sk-estimator-id-365\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-366\" type=\"checkbox\" ><label for=\"sk-estimator-id-366\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">label</label><div class=\"sk-toggleable__content\"><pre>0    quality\n",
       "dtype: object</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-367\" type=\"checkbox\" ><label for=\"sk-estimator-id-367\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-368\" type=\"checkbox\" ><label for=\"sk-estimator-id-368\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function outlier_detection_label at 0x14f6bf100&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-369\" type=\"checkbox\" ><label for=\"sk-estimator-id-369\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function feature_selection at 0x158912020&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('outlier_detection',\n",
       "                                                                   FunctionTransformer(func=<function outlier_detection at 0x15095b240>))]),\n",
       "                                                  Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'magnesium', 'flavanoids', 'minerals', 'calcium', 'chlorides',\n",
       "       'free sulfur dioxid...\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  Index(['wine type'], dtype='object')),\n",
       "                                                 ('label',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  0    quality\n",
       "dtype: object)])),\n",
       "                ('outlier_detection_label',\n",
       "                 FunctionTransformer(func=<function outlier_detection_label at 0x14f6bf100>)),\n",
       "                ('feature_selection',\n",
       "                 FunctionTransformer(func=<function feature_selection at 0x158912020>))])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_pipeline = Pipeline(steps=[\n",
    "])\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\").set_output(transform=\"pandas\")\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy=\"mean\").set_output(transform=\"pandas\")\n",
    "\n",
    "#pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[])\n",
    "categorical_pipeline.steps.append(('imputer', categorical_imputer))\n",
    "categorical_pipeline.steps.append(('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform=\"pandas\")))\n",
    "\n",
    "#pipeline for numerical features\n",
    "numeric_pipeline = Pipeline(steps=[])\n",
    "numeric_pipeline.steps.append(('imputer', numerical_imputer))\n",
    "numeric_pipeline.steps.append(('outlier_detection', outlier_detection))\n",
    "\n",
    "#pipeline for label\n",
    "label_pipeline = Pipeline(steps=[])\n",
    "label_pipeline.steps.append(('imputer', numerical_imputer))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        ('label', label_pipeline, label)\n",
    "    ]).set_output(transform=\"pandas\")\n",
    "cleaning_pipeline.steps.append(('preprocessor', preprocessor))\n",
    "cleaning_pipeline.steps.append((\"outlier_detection_label\", outlier_detection_label))\n",
    "cleaning_pipeline.steps.append(('feature_selection', feature_selection))\n",
    "cleaning_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "training_pipeline_random_forst = Pipeline(\n",
    "    steps=[(\"model\", RandomForestRegressor())]\n",
    ")\n",
    "model = {\n",
    "        \"name\": \"RandomForestRegressor\",\n",
    "        \"estimator\": RandomForestRegressor(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"model__n_estimators\": [200],\n",
    "                \"model__criterion\": [\"squared_error\"],\n",
    "                \"model__max_depth\": [None],\n",
    "                \"model__min_samples_split\": [2],\n",
    "                \"model__min_samples_leaf\": [1]\n",
    "            }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__criterion': 'squared_error', 'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "0.837346033208167\n",
      "0.9143587566685193\n"
     ]
    }
   ],
   "source": [
    "#God Function based on example: LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def god_function(dirty_df):\n",
    "    \n",
    "    clean_df = pd.DataFrame(cleaning_pipeline.fit_transform(dirty_df))\n",
    "    X = clean_df.drop('label__quality', axis=1)\n",
    "    y = clean_df['label__quality']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "    grid = GridSearchCV(training_pipeline_random_forst, model[\"hyperparameters\"], cv=5)\n",
    "    grid = grid.fit(X_train, y_train)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.score(X_test, y_test))\n",
    "\n",
    "god_function(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------colinearity--------\n",
      "High Colinearity between num__residual sugar and num__density with a value of 0.8316095689674599\n",
      "Dropping num__residual sugar because of low correlation -0.07760006766406455 with quality\n",
      "\n",
      "High Colinearity between num__minerals and num__calcium with a value of 0.9032394680532317\n",
      "Dropping num__calcium because of low correlation -0.021263570937899844 with quality\n",
      "\n",
      "High Colinearity between num__chlorides and num__alcohol with a value of 0.5298204778821368\n",
      "Not Dropping num__chlorides because of high correlation -0.1936620103051993 with quality\n",
      "\n",
      "High Colinearity between num__free sulfur dioxide and num__total sulfur dioxide with a value of 0.6048632677816177\n",
      "Dropping num__free sulfur dioxide because of low correlation 0.019648020910944565 with quality\n",
      "\n",
      "High Colinearity between num__total sulfur dioxide and num__density with a value of 0.5523519514518478\n",
      "Not Dropping num__total sulfur dioxide because of high correlation -0.10790569243506681 with quality\n",
      "\n",
      "High Colinearity between num__density and num__alcohol with a value of 0.8058320294868748\n",
      "Not Dropping num__density because of high correlation -0.22713404725253988 with quality\n",
      "\n",
      "High Colinearity between cat__wine type_Gamay and label__quality with a value of 0.6305074660571051\n",
      "Not Dropping cat__wine type_Gamay because of high correlation -0.6305074660571046 with quality\n",
      "\n",
      "Every colinearity is below the threshold of 0.5! \n",
      "\n",
      "--------VIF--------\n",
      "\n",
      "Highest VIF Value, Feature: cat__wine type_Pinot noir with a value of inf\n",
      "Dropping cat__wine type_Pinot noir because of low correlation 0.02862416623866151 with quality\n",
      "\n",
      "Every VIF is below the threshold of 10.0! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9069243948295124\n"
     ]
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(cleaning_pipeline.fit_transform(df))\n",
    "X = clean_df.drop('label__quality', axis=1)\n",
    "y = clean_df['label__quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "best_model = RandomForestRegressor(criterion = 'squared_error', max_depth = None, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200)\n",
    "best_model = best_model.fit(X_train, y_train)\n",
    "print(best_model.score(X_test, y_test))\n",
    "\n",
    "#export best_model with pickle\n",
    "import pickle\n",
    "pickle.dump(best_model, open('best_model__random_forest.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970388005746285\n"
     ]
    }
   ],
   "source": [
    "#load best model with pickle\n",
    "best_model = pickle.load(open('best_model__random_forest.pkl','rb'))\n",
    "#select randomly 1000 data points from df and drop selected ones\n",
    "df_validation = df.sample(n=1000, random_state=1)\n",
    "clean_df = df.drop(df_validation.index)\n",
    "\n",
    "X = clean_df.drop('label__quality', axis=1)\n",
    "y = clean_df['label__quality']\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=200, stratify=y)\n",
    "\n",
    "print(best_model.score(X_validation, y_validation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Meth-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------colinearity--------\n",
      "High Colinearity between num__residual sugar and num__density with a value of 0.830780406761989\n",
      "Dropping num__residual sugar because of low correlation -0.08364822160050356 with quality\n",
      "\n",
      "High Colinearity between num__minerals and num__calcium with a value of 0.9030737715248937\n",
      "Dropping num__calcium because of low correlation -0.02806247904531664 with quality\n",
      "\n",
      "High Colinearity between num__chlorides and num__alcohol with a value of 0.5286770193126731\n",
      "Not Dropping num__chlorides because of high correlation -0.19340534323337397 with quality\n",
      "\n",
      "High Colinearity between num__free sulfur dioxide and num__total sulfur dioxide with a value of 0.6009950373633854\n",
      "Dropping num__free sulfur dioxide because of low correlation 0.013309191783902859 with quality\n",
      "\n",
      "High Colinearity between num__total sulfur dioxide and num__density with a value of 0.5511630654263218\n",
      "Not Dropping num__total sulfur dioxide because of high correlation -0.12018177495915403 with quality\n",
      "\n",
      "High Colinearity between num__density and num__alcohol with a value of 0.8070710394204152\n",
      "Not Dropping num__density because of high correlation -0.23155100567997963 with quality\n",
      "\n",
      "High Colinearity between cat__wine type_Gamay and label__quality with a value of 0.633543918935376\n",
      "Not Dropping cat__wine type_Gamay because of high correlation -0.6335439189353783 with quality\n",
      "\n",
      "Every colinearity is below the threshold of 0.5! \n",
      "\n",
      "--------VIF--------\n",
      "\n",
      "Highest VIF Value, Feature: cat__wine type_Pinot noir with a value of inf\n",
      "Dropping cat__wine type_Pinot noir because of low correlation 0.030957289858199993 with quality\n",
      "\n",
      "Every VIF is below the threshold of 10.0! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "df_validation = df.sample(n=1000, random_state=42)\n",
    "\n",
    "clean_df = df.drop(df_validation.index)\n",
    "clean_df = pd.DataFrame(cleaning_pipeline.fit_transform(clean_df))\n",
    "\n",
    "X_clean = clean_df.drop('label__quality', axis=1)\n",
    "y_clean = clean_df['label__quality']\n",
    "\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean, test_size=0.2, random_state=200, stratify=y_clean)\n",
    "best_model = RandomForestRegressor(criterion = 'squared_error', max_depth = None, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200)\n",
    "best_model = best_model.fit(X_train_clean, y_train_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.857862219133906"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------colinearity--------\n",
      "High Colinearity between num__residual sugar and num__density with a value of 0.83747432504066\n",
      "Dropping num__residual sugar because of low correlation -0.03841622427373328 with quality\n",
      "\n",
      "High Colinearity between num__minerals and num__calcium with a value of 0.8940828932837327\n",
      "Dropping num__minerals because of low correlation 0.020731400128316195 with quality\n",
      "\n",
      "High Colinearity between num__chlorides and num__alcohol with a value of 0.5384231056394151\n",
      "Not Dropping num__chlorides because of high correlation -0.20146010910088719 with quality\n",
      "\n",
      "High Colinearity between num__free sulfur dioxide and num__total sulfur dioxide with a value of 0.6284853559467134\n",
      "Dropping num__total sulfur dioxide because of low correlation -0.02969884939978694 with quality\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'num__total sulfur dioxide'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num__total sulfur dioxide'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[302], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_validation \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(cleaning_pipeline\u001b[39m.\u001b[39;49mfit_transform(df_validation))\n\u001b[1;32m      2\u001b[0m X_validation \u001b[39m=\u001b[39m df_validation\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mlabel__quality\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m y_validation \u001b[39m=\u001b[39m df_validation[\u001b[39m'\u001b[39m\u001b[39mlabel__quality\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sklearn/pipeline.py:445\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    443\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39;49mfit_transform(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    446\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:238\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m    Transformed input.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X, func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, kw_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkw_args)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:310\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     func \u001b[39m=\u001b[39m _identity\n\u001b[0;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m func(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(kw_args \u001b[39mif\u001b[39;49;00m kw_args \u001b[39melse\u001b[39;49;00m {}))\n",
      "Cell \u001b[0;32mIn[292], line 30\u001b[0m, in \u001b[0;36mfeature_selection\u001b[0;34m(df, colinearity_threshold, correlation_threshold, vif_threshold)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--------colinearity--------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m col1, col2 \u001b[39min\u001b[39;00m colinear_columns:\n\u001b[0;32m---> 30\u001b[0m     corr_col1 \u001b[39m=\u001b[39m df[col1]\u001b[39m.\u001b[39mcorr(df[\u001b[39m'\u001b[39m\u001b[39mlabel__quality\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m     corr_col2 \u001b[39m=\u001b[39m df[col2]\u001b[39m.\u001b[39mcorr(df[\u001b[39m'\u001b[39m\u001b[39mlabel__quality\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mHigh Colinearity between \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m col1 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mcol2 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m with a value of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(colinearity_values[col1, col2]))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num__total sulfur dioxide'"
     ]
    }
   ],
   "source": [
    "df_validation = pd.DataFrame(cleaning_pipeline.fit_transform(df_validation))\n",
    "X_validation = df_validation.drop('label__quality', axis=1)\n",
    "y_validation = df_validation['label__quality']\n",
    "\n",
    "best_model.score(X_validation, y_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
